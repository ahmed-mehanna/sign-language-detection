{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c03c2d",
   "metadata": {},
   "source": [
    "# 1 - install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bffa97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab75ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "num_hand_marks = 21\n",
    "num_pose_marks = 33\n",
    "\n",
    "\n",
    "pose_selected_landmarks = [\n",
    "    [0,2,5,11,13,15,12,14,16],\n",
    "    [0,2,4,5,8,9,12,13,16,17,20],\n",
    "    [0,2,4,5,8,9,12,13,16,17,20],\n",
    "]\n",
    "\n",
    "def draw_updated_styled(image,results):\n",
    "    image_rows, image_cols, _ = image.shape\n",
    "    \n",
    "    original_landmarks = [\n",
    "        results.pose_landmarks,\n",
    "        results.left_hand_landmarks,\n",
    "        results.right_hand_landmarks\n",
    "    ]\n",
    "\n",
    "    \n",
    "    for shape in range(3):\n",
    "        if(original_landmarks[shape]):\n",
    "            lis = original_landmarks[shape].landmark\n",
    "            for idx in pose_selected_landmarks[shape]:\n",
    "                point = lis[idx]\n",
    "                landmark_px = mp_drawing._normalized_to_pixel_coordinates(point.x, point.y,\n",
    "                                                           image_cols, image_rows)\n",
    "\n",
    "                cv2.circle(image, landmark_px, 2, (0,0,255),\n",
    "                         4)     \n",
    "                \n",
    "def extract_keypoints(results):\n",
    "    \n",
    "    original_landmarks = [\n",
    "        results.pose_landmarks,\n",
    "        results.left_hand_landmarks,\n",
    "        results.right_hand_landmarks\n",
    "    ]\n",
    "    \n",
    "    outputs = []\n",
    "    for shape in range(3):\n",
    "        if(original_landmarks[shape]):\n",
    "            lis = original_landmarks[shape].landmark\n",
    "            pose = np.array([ [lis[res].x,lis[res].y] for res in pose_selected_landmarks[shape] ]).flatten()\n",
    "        else:\n",
    "            pose = np.zeros(len(pose_selected_landmarks[shape])*2)\n",
    "        outputs.append(pose)\n",
    "    return np.concatenate([outputs[0],outputs[1],outputs[2]])\n",
    "\n",
    "\n",
    "\n",
    "# holistic model process image and return the results as keypoints\n",
    "def mediapipe_detection(image,model):\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33dcd736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sister', 'hurry', 'hungry', 'meal', 'brother', 'tree', 'heavy', 'cry', 'family', 'wise'] {'sister': 0, 'hurry': 1, 'hungry': 2, 'meal': 3, 'brother': 4, 'tree': 5, 'heavy': 6, 'cry': 7, 'family': 8, 'wise': 9}\n"
     ]
    }
   ],
   "source": [
    "actions = ['sister','hurry','hungry','meal','brother','tree','heavy','cry','family','wise']\n",
    "dic={}\n",
    "for i,action in enumerate(actions):\n",
    "    dic[action]=i\n",
    "\n",
    "print(actions,dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742a5d4",
   "metadata": {},
   "source": [
    "# 4 - build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c15994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Input,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "best_model_file_name = os.path.join(\"weights\",\"V1.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfdeb079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 16, 62)]          0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 16, 64)            32512     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 16, 128)           98816     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 96)                86400     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224,586\n",
      "Trainable params: 224,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def V1():\n",
    "    input_layer = Input(shape=(16,62))\n",
    "    layer = LSTM(64,return_sequences=True,activation=\"relu\")(input_layer)\n",
    "    layer = LSTM(128,return_sequences=True,activation=\"relu\")(layer)\n",
    "    layer = LSTM(96,return_sequences=False,activation=\"relu\")(layer)\n",
    "    layer = Dense(64,activation=\"relu\")(layer)\n",
    "    layer = Dense(len(actions),activation=\"softmax\")(layer)\n",
    "\n",
    "    \n",
    "    model = Model(inputs=input_layer,outputs=layer)\n",
    "    model.compile(optimizer=\"Adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def V2():\n",
    "    input_layer = Input(shape=(16,62))\n",
    "    layer = LSTM(64,return_sequences=True,activation=\"relu\")(input_layer)\n",
    "    layer = LSTM(128,return_sequences=True,activation=\"relu\")(layer)\n",
    "    layer = LSTM(256,return_sequences=True,activation=\"relu\")(layer)\n",
    "    layer = LSTM(128,return_sequences=True,activation=\"relu\")(layer)\n",
    "    layer = LSTM(64,return_sequences=False,activation=\"relu\")(layer)\n",
    "    layer = Dense(64,activation=\"relu\")(layer)\n",
    "    layer = Dense(len(actions),activation=\"softmax\")(layer)\n",
    "\n",
    "    model = Model(inputs=input_layer,outputs=layer)\n",
    "    model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def second_model():\n",
    "    input_layer = Input(shape=(20,62))\n",
    "    layer = LSTM(64,return_sequences=True,activation=\"relu\")(input_layer)\n",
    "    layer = LSTM(128,return_sequences=True,activation=\"relu\")(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = LSTM(256,return_sequences=True,activation=\"relu\")(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = LSTM(128,return_sequences=True,activation=\"relu\")(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = LSTM(64,return_sequences=False,activation=\"relu\")(layer)\n",
    "    layer = Dense(64,activation=\"relu\")(layer)\n",
    "    layer = Dense(len(actions),activation=\"softmax\")(layer)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_layer,outputs=layer)\n",
    "    model.compile(optimizer=\"Adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = V1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f30a6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(best_model_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743e09c",
   "metadata": {},
   "source": [
    "# 5 - test in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5464f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad45443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def view_probability(res, actions, image):\n",
    "    #output_frame = input_frame.copy()\n",
    "    \n",
    "    output_frame = image\n",
    "    height,width,_ = image.shape\n",
    "    \n",
    "    if(type(res)==list or type(res)==np.ndarray):\n",
    "        max_prob_index = np.argmax(res)\n",
    "        max_prob = res[max_prob_index]\n",
    "        text = f'{actions[max_prob_index]} - {max_prob:.3f}'\n",
    "    else:\n",
    "        text = \"not signing\"\n",
    "    \n",
    "    \n",
    "    cv2.rectangle(output_frame, (0,0), (width, 40), (0,255,0), -1)\n",
    "    cv2.putText(output_frame, text, (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame\n",
    "\n",
    "\n",
    "\n",
    "def view_sentence(sentence,image):\n",
    "    # output_frame = image.copy()\n",
    "    output_frame = image\n",
    "    height,width,_ = image.shape\n",
    "    cv2.rectangle(output_frame, (0,height-40), (width, height), (255, 0, 0), -1)\n",
    "    cv2.putText(output_frame, ' '.join(sentence), (10,height-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return output_frame\n",
    "\n",
    "\n",
    "def compare_frames(prev_frame,current_frame,threshold):\n",
    "    return True\n",
    "    if(type(prev_frame) == np.ndarray ):\n",
    "        diff = cv2.absdiff(prev_frame, current_frame)\n",
    "        s = diff.sum()\n",
    "        if(s > threshold):\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "    \n",
    "def evaluate_list_comparisons(s):\n",
    "    return True\n",
    "    if(sum(s)>=2):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a888db6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1. New detection variables\n",
    "sequence = [np.zeros(62)]\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "n_frames = 16\n",
    "\n",
    "res = None\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "\n",
    "last_comparisons = []\n",
    "holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "prev_frame = None\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if(not ret):break\n",
    "        \n",
    "    frame = cv2.resize(frame,(512,512))\n",
    "        \n",
    "        \n",
    "    comparison_result = compare_frames(prev_frame,frame,4000000)\n",
    "    prev_frame = frame\n",
    "    \n",
    "    last_comparisons.append(int(comparison_result))\n",
    "    last_comparisons = last_comparisons[-2:]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    image, results = mediapipe_detection(frame, holistic)\n",
    "    draw_updated_styled(image, results)\n",
    "\n",
    "    # 2. Prediction logic\n",
    "    \n",
    "    \n",
    "    if(evaluate_list_comparisons(last_comparisons)):\n",
    "        keypoints = extract_keypoints(results)\n",
    "#         for ind,n in enumerate(keypoints):\n",
    "#             if keypoints[ind]==0:\n",
    "#                 keypoints[ind] = sequence[-1][ind]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-n_frames:]\n",
    "\n",
    "        if len(sequence) == n_frames:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            predictions.append(np.argmax(res))\n",
    "\n",
    "\n",
    "        #3. Viz logic\n",
    "            if np.unique(predictions[-2:])[0]==np.argmax(res): \n",
    "                if res[np.argmax(res)] > threshold: \n",
    "\n",
    "                    if len(sentence) > 0: \n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "    else:\n",
    "        res = None\n",
    "\n",
    "\n",
    "    image = cv2.resize(image,(840,640))\n",
    "    \n",
    "    image = view_probability(res, actions, image)\n",
    "    image = view_sentence(sentence,image)\n",
    "    \n",
    "\n",
    "    \n",
    "    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "    # Break\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca692265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 840, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7429ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4683df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6069613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = np.array([5,2,2,2,2,2])\n",
    "test = np.array([5,2,3,0,5,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a58720dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 3, 0, 5, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test&test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec6ae2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,n in enumerate(test):\n",
    "    if test[ind]==0:test[ind] = old[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b283ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 3, 2, 5, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d56b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
